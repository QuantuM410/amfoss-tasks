The web scraping part was pretty easy using class ids etc from the webpage HTML (I had a problem in scraping 24 hour change data) but everything else 
went well. I left the task at that after one sitting.
When I sat next time to write csv file I added csv dependency but now my scraper dependency was having some problem loading in the mainrs file and I tried
to fix it but it didnt so I wrote a proxymain.rs code where I wrote how I would have attempted to write the csv in my first attempt.
